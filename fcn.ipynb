{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, UpSampling3D, Conv2DTranspose, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from PIL import Image as PImage\n",
    "#import cv2\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import tqdm as tqdm\n",
    "import skimage.measure\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from numpy import unravel_index\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are importing the images and downsizing it to 100x100 images. \n",
    "# We downsize the image by taking mean of every 10 pixel of the image. \n",
    "# We have normalised  the dataset to constrain the value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 1)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//rotated images//1_60//1_60_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr1 = np.zeros(shape = (100,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "for img in range(100):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr1[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "arr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//rotated images//3_60//3_60_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr2 = np.zeros(shape = (100,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "\n",
    "for img in range(100):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    \n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr2[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr2 = arr2[:,::10,::10,:]\n",
    "arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//rotated images//5_60//5_60_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr3 = np.zeros(shape = (100,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "\n",
    "for img in range(100):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr3[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr3 = arr3[:,::10,::10,:]\n",
    "arr3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//rotated images//1_40//1_40_\"\n",
    "\n",
    "#v = np.zeros(shape = (1000,1000))\n",
    "arr6 = np.zeros(shape = (100,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "for img in range(100):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr6[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr6 = arr6[:,::10,::10,:]\n",
    "arr6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 100, 100, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//rotated images//3_40//3_40_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr7 = np.zeros(shape = (58,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "for img in range(58):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr7[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr7 = arr7[:,::10,::10,:]\n",
    "arr7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 100, 100, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//rotated images//10_60//10_60_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr8 = np.zeros(shape = (71,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "for img in range(71):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr8[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr8 = arr8[:,::10,::10,:]\n",
    "arr8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//rotated images//10_40//10_40_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr9 = np.zeros(shape = (100,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "for img in range(100):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr9[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr9 = arr9[:,::10,::10,:]\n",
    "arr9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 100, 100, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//rotated images//15_40//15_40_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr10 = np.zeros(shape = (78,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "for img in range(78):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr10[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr10 = arr10[:,::10,::10,:]\n",
    "arr10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 100, 100, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//new_images//20_40//20_40_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr14 = np.zeros(shape = (40,100,100,1))\n",
    "#i = 0\n",
    "j = 11\n",
    "\n",
    "for i in range(40):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr14[i,:,:,0] = v\n",
    "    #i = i + 1\n",
    "    j = j + 1\n",
    "#arr14 = arr14[:,::10,::10,:]\n",
    "arr14.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 100, 1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//new_images//1_40//1_40_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr11 = np.zeros(shape = (50,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "\n",
    "for img in range(50):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr11[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr11 = arr11[:,::10,::10,:]\n",
    "arr11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 100, 1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//new_images//1_60//1_60_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr12 = np.zeros(shape = (50,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "\n",
    "for img in range(50):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr12[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr12 = arr12[:,::10,::10,:]\n",
    "arr12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 100, 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//new_images//3_60//3_60_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr13 = np.zeros(shape = (50,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "\n",
    "for img in range(50):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr13[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr13 = arr13[:,::10,::10,:]\n",
    "arr13.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 100, 1)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//new_images//20_40//20_40_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr15 = np.zeros(shape = (10,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "\n",
    "for img in range(10):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr15[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr15 = arr15[:,::10,::10,:]\n",
    "arr15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 100, 100, 1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C://Users//012480156//Downloads//new_images//15_40//15_40_\"\n",
    "\n",
    "v = np.zeros(shape = (1000,1000))\n",
    "arr16 = np.zeros(shape = (25,100,100,1))\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "\n",
    "for img in range(25):\n",
    "    img  = PImage.open(path + str(j) + \".png\")\n",
    "    img = img.transpose(PImage.FLIP_TOP_BOTTOM)\n",
    "    v = np.array(img)\n",
    "    \n",
    "    v = skimage.measure.block_reduce(v, (10,10), np.mean)\n",
    "    v = normalize(v, axis=1, norm='l2')\n",
    "    #v = (v - np.min(v))/np.ptp(v)\n",
    "    #v = skimage.measure.block_reduce(v, (10,10), np.max)\n",
    "    arr16[i,:,:,0] = v\n",
    "    i = i + 1\n",
    "    j = j + 1\n",
    "#arr16 = arr16[:,::10,::10,:]\n",
    "arr16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are importing the stress matrix and downsizing it to 100x100 matrix. \n",
    "# We downsize the matrix by taking mean of every 10 pixel of the image. \n",
    "# We have normalised  the dataset to constrain the value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat1 = np.zeros(shape = (100,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//train//1_60_copy//1_60_\"\n",
    "for j in range(1,101):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    \n",
    "    arr_mat1[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat2 = np.zeros(shape = (100,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//train//3_60_copy//3_60_\"\n",
    "for j in range(1,101):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    \n",
    "    arr_mat2[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat3 = np.zeros(shape = (100,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//train//5_60_copy//5_60_\"\n",
    "for j in range(1,101):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat3[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 1)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat6 = np.zeros(shape = (100,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//train//1_40//1_40_\"\n",
    "for j in range(1,101):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat6[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 100, 100, 1)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat7 = np.zeros(shape = (58,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//train//3_40//stress_matrix_3_40_\"\n",
    "for j in range(1,59):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    \n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat7[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 100, 100, 1)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat8 = np.zeros(shape = (71,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//train//10_60//stress_matrix_10_60_\"\n",
    "for j in range(1,72):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    \n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat8[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat9 = np.zeros(shape = (100,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//train//10_40//stress_matrix_10_40_\"\n",
    "for j in range(1,101):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    \n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat9[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 100, 100, 1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat10 = np.zeros(shape = (78,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//train//15_40//stress_matrix_15_40_\"\n",
    "for j in range(1,79):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    \n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat10[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 100, 100, 1)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat14 = np.zeros(shape = (40,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//train//20_40//20_40_\"\n",
    "for j in range(11,51):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    \n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat14[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat14.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 100, 1)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat11 = np.zeros(shape = (50,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//test//1_40_new//1_40_\"\n",
    "for j in range(1,51):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    \n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat11[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 100, 1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat12 = np.zeros(shape = (50,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//test//1_60_new//1_60_\"\n",
    "for j in range(1,51):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    #print(df.shape)\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    \n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat12[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 100, 1)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat13 = np.zeros(shape = (50,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//test//3_60_new//3_60_\"\n",
    "for j in range(1,51):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    \n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat13[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat13.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 100, 1)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat15 = np.zeros(shape = (10,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//test//20_40_new//20_40_\"\n",
    "for j in range(1,11):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    \n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat15[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 100, 100, 1)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mat16 = np.zeros(shape = (25,100,100,1))\n",
    "i = 0\n",
    "path = \"C://Users//012480156//Downloads//y_stress_mat//test//15_40_new//15_40_\"\n",
    "for j in range(1,26):\n",
    "    j = str(j)\n",
    "    df = pd.read_csv(path + j + \".csv\" , header = None)\n",
    "    #df = pd.qcut(df.ix[:,0], 20, labels=False, duplicates='drop')\n",
    "    df = df.as_matrix()\n",
    "    df = np.reshape(df, (1000,1000))\n",
    "    \n",
    "    df = skimage.measure.block_reduce(df, (10,10), np.mean)\n",
    "    df = normalize(df, axis=1, norm='l2')\n",
    "    #df = (df - np.min(df))/np.ptp(df)\n",
    "    #df = skimage.measure.block_reduce(df, (10,10), np.max)\n",
    "    \n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = np.divide(df, df.max())\n",
    "    #df = df[::10,::10]\n",
    "    arr_mat16[i,:,:,0] = df\n",
    "    i = i + 1\n",
    "arr_mat16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((arr1,arr2,arr3,arr6,arr7,arr8,arr9,arr10,arr14), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((arr_mat1,arr_mat2,arr_mat3,arr_mat6,arr_mat7,arr_mat8,arr_mat9,arr_mat10,arr_mat14), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 100, 100, 1)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ts = np.concatenate((arr11,arr12,arr13,arr15,arr16), axis = 0)\n",
    "x_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 100, 100, 1)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ts = np.concatenate((arr_mat11,arr_mat12,arr_mat13,arr_mat15,arr_mat16), axis = 0)\n",
    "y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the FCN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_140 (Conv2D)          (None, 100, 100, 32)      544       \n",
      "_________________________________________________________________\n",
      "conv2d_141 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_144 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_147 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_148 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_149 (Conv2D)          (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_150 (Conv2D)          (None, 100, 100, 32)      4128      \n",
      "_________________________________________________________________\n",
      "conv2d_151 (Conv2D)          (None, 100, 100, 32)      4128      \n",
      "_________________________________________________________________\n",
      "conv2d_152 (Conv2D)          (None, 100, 100, 32)      4128      \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 100, 100, 32)      4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_154 (Conv2D)          (None, 50, 50, 64)        32832     \n",
      "_________________________________________________________________\n",
      "conv2d_155 (Conv2D)          (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_156 (Conv2D)          (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_157 (Conv2D)          (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_158 (Conv2D)          (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_160 (Conv2D)          (None, 50, 50, 64)        16448     \n",
      "_________________________________________________________________\n",
      "conv2d_161 (Conv2D)          (None, 50, 50, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_162 (Conv2D)          (None, 25, 25, 128)       131200    \n",
      "_________________________________________________________________\n",
      "conv2d_163 (Conv2D)          (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_164 (Conv2D)          (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_165 (Conv2D)          (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_166 (Conv2D)          (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_167 (Conv2D)          (None, 25, 25, 128)       65664     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 100, 100, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 100, 100, 1)       1153      \n",
      "=================================================================\n",
      "Total params: 1,139,009\n",
      "Trainable params: 1,139,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(4 , 4), activation='relu', padding='same', input_shape=(100,100,1)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(4, 4), activation='relu', padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(4, 4), activation='relu', padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, kernel_size=(2, 2), activation='relu', padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "#model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Conv2DTranspose(128, kernel_size=(3,3), padding='same', data_format=None, activation='relu'))\n",
    "#model.add(UpSampling2D(size=(2,2), data_format=None, interpolation='nearest'))\n",
    "\n",
    "model.add(UpSampling2D(size=(4,4), data_format=None, interpolation='nearest'))\n",
    "#model.add(Conv2DTranspose(128, kernel_size=(3,3), padding='same', data_format=None, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2DTranspose(1, kernel_size=(3,3), padding='same', data_format=None, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#model.add(UpSampling2D(size=(2,2), data_format=None, interpolation='nearest'))\n",
    "#model.add(Conv2DTranspose(64, kernel_size=(3,3), padding='same', data_format=None, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv2DTranspose(64, kernel_size=(3,3), padding='same', data_format=None, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#model.add(UpSampling2D(size=(2,2), data_format=None, interpolation='nearest'))\n",
    "#model.add(Conv2DTranspose(32, kernel_size=(3,3), padding='same', data_format=None, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv2DTranspose(32, kernel_size=(3,3), padding='same', data_format=None, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#model.add(Conv2D(1, kernel_size=(3,3), padding='same', data_format=None, activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.mean_squared_error, optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "747/747 [==============================] - 14s 18ms/step - loss: 0.0064\n",
      "Epoch 2/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 0.0018\n",
      "Epoch 3/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 0.0012\n",
      "Epoch 4/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 0.0010\n",
      "Epoch 5/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 0.0010\n",
      "Epoch 6/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.8278e-04\n",
      "Epoch 7/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.6542e-04\n",
      "Epoch 8/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.5547e-04\n",
      "Epoch 9/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.4612e-04\n",
      "Epoch 10/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.3758e-04\n",
      "Epoch 11/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.3084e-04\n",
      "Epoch 12/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.2159e-04\n",
      "Epoch 13/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.1258e-04\n",
      "Epoch 14/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.0393e-04\n",
      "Epoch 15/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.9484e-04\n",
      "Epoch 16/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.9583e-04\n",
      "Epoch 17/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.8578e-04\n",
      "Epoch 18/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.7094e-04\n",
      "Epoch 19/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.5888e-04\n",
      "Epoch 20/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.6626e-04\n",
      "Epoch 21/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.3589e-04\n",
      "Epoch 22/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.2254e-04\n",
      "Epoch 23/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.1554e-04\n",
      "Epoch 24/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.0051e-04\n",
      "Epoch 25/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.1957e-04\n",
      "Epoch 26/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.8843e-04\n",
      "Epoch 27/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.8063e-04\n",
      "Epoch 28/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7703e-04\n",
      "Epoch 29/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.8023e-04\n",
      "Epoch 30/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.8323e-04\n",
      "Epoch 31/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7526e-04\n",
      "Epoch 32/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7423e-04\n",
      "Epoch 33/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7210e-04\n",
      "Epoch 34/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7360e-04\n",
      "Epoch 35/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7278e-04\n",
      "Epoch 36/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7089e-04\n",
      "Epoch 37/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.6770e-04\n",
      "Epoch 38/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.6580e-04\n",
      "Epoch 39/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.6391e-04\n",
      "Epoch 40/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.6230e-04\n",
      "Epoch 41/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7240e-04\n",
      "Epoch 42/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7600e-04\n",
      "Epoch 43/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.6820e-04\n",
      "Epoch 44/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.6032e-04\n",
      "Epoch 45/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.6153e-04\n",
      "Epoch 46/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.5768e-04\n",
      "Epoch 47/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.4840e-04\n",
      "Epoch 48/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.4660e-04\n",
      "Epoch 49/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9060e-04\n",
      "Epoch 50/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6566e-04\n",
      "Epoch 51/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 4.7331e-04\n",
      "Epoch 52/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 4.3951e-04\n",
      "Epoch 53/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 3.9880e-04\n",
      "Epoch 54/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 3.6503e-04\n",
      "Epoch 55/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 3.2325e-04\n",
      "Epoch 56/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 2.9589e-04\n",
      "Epoch 57/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 2.9412e-04\n",
      "Epoch 58/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 2.6489e-04\n",
      "Epoch 59/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 2.4398e-04\n",
      "Epoch 60/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 2.5149e-04\n",
      "Epoch 61/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 2.2673e-04\n",
      "Epoch 62/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 2.0804e-04\n",
      "Epoch 63/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.9167e-04\n",
      "Epoch 64/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.8617e-04\n",
      "Epoch 65/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 2.5686e-04\n",
      "Epoch 66/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 2.1015e-04\n",
      "Epoch 67/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.8765e-04\n",
      "Epoch 68/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.7491e-04\n",
      "Epoch 69/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.6476e-04\n",
      "Epoch 70/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.5315e-04\n",
      "Epoch 71/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.4506e-04\n",
      "Epoch 72/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.3874e-04\n",
      "Epoch 73/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.3540e-04\n",
      "Epoch 74/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.3368e-04\n",
      "Epoch 75/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.2866e-04\n",
      "Epoch 76/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.5004e-04\n",
      "Epoch 77/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.4369e-04\n",
      "Epoch 78/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.2855e-04\n",
      "Epoch 79/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.2192e-04\n",
      "Epoch 80/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.1662e-04\n",
      "Epoch 81/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.1253e-04\n",
      "Epoch 82/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.0903e-04\n",
      "Epoch 83/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.0685e-04\n",
      "Epoch 84/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.0524e-04\n",
      "Epoch 85/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.0695e-04\n",
      "Epoch 86/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.0708e-04\n",
      "Epoch 87/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.0495e-04\n",
      "Epoch 88/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.0793e-04\n",
      "Epoch 89/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.1377e-04\n",
      "Epoch 90/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.1100e-04\n",
      "Epoch 91/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.1032e-04\n",
      "Epoch 92/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 1.0509e-04\n",
      "Epoch 93/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.9343e-05\n",
      "Epoch 94/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.6441e-05\n",
      "Epoch 95/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.4587e-05\n",
      "Epoch 96/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.1587e-05\n",
      "Epoch 97/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.9850e-05\n",
      "Epoch 98/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.8096e-05\n",
      "Epoch 99/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.6830e-05\n",
      "Epoch 100/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.5952e-05\n",
      "Epoch 101/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.5858e-05\n",
      "Epoch 102/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.6098e-05\n",
      "Epoch 103/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.6898e-05\n",
      "Epoch 104/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.2961e-05\n",
      "Epoch 105/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.2483e-05\n",
      "Epoch 106/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.2674e-05\n",
      "Epoch 107/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.7763e-05\n",
      "Epoch 108/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.6268e-05\n",
      "Epoch 109/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.3503e-05\n",
      "Epoch 110/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.2745e-05\n",
      "Epoch 111/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.3946e-05\n",
      "Epoch 112/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.7262e-05\n",
      "Epoch 113/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 9.9568e-05\n",
      "Epoch 114/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.9139e-05\n",
      "Epoch 115/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.6095e-05\n",
      "Epoch 116/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.3621e-05\n",
      "Epoch 117/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.1835e-05\n",
      "Epoch 118/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.1469e-05\n",
      "Epoch 119/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 8.0215e-05\n",
      "Epoch 120/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.8688e-05\n",
      "Epoch 121/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7560e-05\n",
      "Epoch 122/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.7018e-05\n",
      "Epoch 123/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.5273e-05\n",
      "Epoch 124/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.5151e-05\n",
      "Epoch 125/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.5295e-05\n",
      "Epoch 126/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.3948e-05\n",
      "Epoch 127/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.2732e-05\n",
      "Epoch 128/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.3298e-05\n",
      "Epoch 129/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.6506e-05\n",
      "Epoch 130/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.5051e-05\n",
      "Epoch 131/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.5385e-05\n",
      "Epoch 132/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.3168e-05\n",
      "Epoch 133/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.0767e-05\n",
      "Epoch 134/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.1096e-05\n",
      "Epoch 135/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.9378e-05\n",
      "Epoch 136/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.1873e-05\n",
      "Epoch 137/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.0583e-05\n",
      "Epoch 138/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.9486e-05\n",
      "Epoch 139/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.0620e-05\n",
      "Epoch 140/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.9308e-05\n",
      "Epoch 141/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.0309e-05\n",
      "Epoch 142/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.0263e-05\n",
      "Epoch 143/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.9477e-05\n",
      "Epoch 144/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.5403e-05\n",
      "Epoch 145/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.2541e-05\n",
      "Epoch 146/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.1676e-05\n",
      "Epoch 147/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.1272e-05\n",
      "Epoch 148/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.9752e-05\n",
      "Epoch 149/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.8242e-05\n",
      "Epoch 150/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.8652e-05\n",
      "Epoch 151/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.7496e-05\n",
      "Epoch 152/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.7913e-05\n",
      "Epoch 153/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.7771e-05\n",
      "Epoch 154/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.5943e-05\n",
      "Epoch 155/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.6088e-05\n",
      "Epoch 156/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.5650e-05\n",
      "Epoch 157/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.4452e-05\n",
      "Epoch 158/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.0457e-05\n",
      "Epoch 159/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.1175e-05\n",
      "Epoch 160/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 7.1104e-05\n",
      "Epoch 161/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.8686e-05\n",
      "Epoch 162/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.8670e-05\n",
      "Epoch 163/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.9533e-05\n",
      "Epoch 164/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.6921e-05\n",
      "Epoch 165/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.5621e-05\n",
      "Epoch 166/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.4858e-05\n",
      "Epoch 167/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.4193e-05\n",
      "Epoch 168/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.5504e-05\n",
      "Epoch 169/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.7337e-05\n",
      "Epoch 170/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.4587e-05\n",
      "Epoch 171/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.4513e-05\n",
      "Epoch 172/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.3973e-05\n",
      "Epoch 173/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2439e-05\n",
      "Epoch 174/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2363e-05\n",
      "Epoch 175/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.3066e-05\n",
      "Epoch 176/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2365e-05\n",
      "Epoch 177/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.6328e-05\n",
      "Epoch 178/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.6381e-05\n",
      "Epoch 179/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2826e-05\n",
      "Epoch 180/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2326e-05\n",
      "Epoch 181/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2346e-05\n",
      "Epoch 182/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2979e-05\n",
      "Epoch 183/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2588e-05\n",
      "Epoch 184/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2699e-05\n",
      "Epoch 185/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2798e-05\n",
      "Epoch 186/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2219e-05\n",
      "Epoch 187/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2810e-05\n",
      "Epoch 188/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.3095e-05\n",
      "Epoch 189/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.3142e-05\n",
      "Epoch 190/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2716e-05\n",
      "Epoch 191/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.1943e-05\n",
      "Epoch 192/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.1250e-05\n",
      "Epoch 193/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.3984e-05\n",
      "Epoch 194/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.1809e-05\n",
      "Epoch 195/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2666e-05\n",
      "Epoch 196/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.9264e-05\n",
      "Epoch 197/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.7415e-05\n",
      "Epoch 198/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.7980e-05\n",
      "Epoch 199/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2529e-05\n",
      "Epoch 200/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.3296e-05\n",
      "Epoch 201/600\n",
      "747/747 [==============================] - 9s 12ms/step - loss: 6.3646e-05\n",
      "Epoch 202/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0700e-05\n",
      "Epoch 203/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0773e-05\n",
      "Epoch 204/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0523e-05\n",
      "Epoch 205/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0102e-05\n",
      "Epoch 206/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0571e-05\n",
      "Epoch 207/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9465e-05\n",
      "Epoch 208/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9082e-05\n",
      "Epoch 209/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8564e-05\n",
      "Epoch 210/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8712e-05\n",
      "Epoch 211/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8678e-05\n",
      "Epoch 212/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9065e-05\n",
      "Epoch 213/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8388e-05\n",
      "Epoch 214/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9097e-05\n",
      "Epoch 215/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2127e-05\n",
      "Epoch 216/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2834e-05\n",
      "Epoch 217/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.4477e-05\n",
      "Epoch 218/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.1508e-05\n",
      "Epoch 219/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2425e-05\n",
      "Epoch 220/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0331e-05\n",
      "Epoch 221/600\n",
      "747/747 [==============================] - 9s 12ms/step - loss: 5.8822e-05\n",
      "Epoch 222/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8357e-05\n",
      "Epoch 223/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8615e-05\n",
      "Epoch 224/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9220e-05\n",
      "Epoch 225/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7959e-05\n",
      "Epoch 226/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9894e-05\n",
      "Epoch 227/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9259e-05\n",
      "Epoch 228/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8818e-05\n",
      "Epoch 229/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9735e-05\n",
      "Epoch 230/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8045e-05\n",
      "Epoch 231/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8666e-05\n",
      "Epoch 232/600\n",
      "747/747 [==============================] - 9s 12ms/step - loss: 5.9036e-05\n",
      "Epoch 233/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9455e-05\n",
      "Epoch 234/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7728e-05\n",
      "Epoch 235/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8826e-05\n",
      "Epoch 236/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9461e-05\n",
      "Epoch 237/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8825e-05\n",
      "Epoch 238/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.1032e-05\n",
      "Epoch 239/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8931e-05\n",
      "Epoch 240/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9141e-05\n",
      "Epoch 241/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.1434e-05\n",
      "Epoch 242/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0048e-05\n",
      "Epoch 243/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9503e-05\n",
      "Epoch 244/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0460e-05\n",
      "Epoch 245/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8751e-05\n",
      "Epoch 246/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8778e-05\n",
      "Epoch 247/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7146e-05\n",
      "Epoch 248/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8112e-05\n",
      "Epoch 249/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6976e-05\n",
      "Epoch 250/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8083e-05\n",
      "Epoch 251/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6972e-05\n",
      "Epoch 252/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7986e-05\n",
      "Epoch 253/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8994e-05\n",
      "Epoch 254/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.1832e-05\n",
      "Epoch 255/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2379e-05\n",
      "Epoch 256/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9858e-05\n",
      "Epoch 257/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8683e-05\n",
      "Epoch 258/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.3120e-05\n",
      "Epoch 259/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2713e-05\n",
      "Epoch 260/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.1018e-05\n",
      "Epoch 261/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.1445e-05\n",
      "Epoch 262/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.2074e-05\n",
      "Epoch 263/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0802e-05\n",
      "Epoch 264/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9458e-05\n",
      "Epoch 265/600\n",
      "747/747 [==============================] - 9s 12ms/step - loss: 6.0406e-05\n",
      "Epoch 266/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7860e-05\n",
      "Epoch 267/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7371e-05\n",
      "Epoch 268/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7324e-05\n",
      "Epoch 269/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7723e-05\n",
      "Epoch 270/600\n",
      "747/747 [==============================] - 9s 12ms/step - loss: 5.7099e-05\n",
      "Epoch 271/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7277e-05\n",
      "Epoch 272/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7456e-05\n",
      "Epoch 273/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7081e-05\n",
      "Epoch 274/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8547e-05\n",
      "Epoch 275/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7356e-05\n",
      "Epoch 276/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5478e-05\n",
      "Epoch 277/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5713e-05\n",
      "Epoch 278/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6040e-05\n",
      "Epoch 279/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5166e-05\n",
      "Epoch 280/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5044e-05\n",
      "Epoch 281/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5347e-05\n",
      "Epoch 282/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5774e-05\n",
      "Epoch 283/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5386e-05\n",
      "Epoch 284/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6244e-05\n",
      "Epoch 285/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6342e-05\n",
      "Epoch 286/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8055e-05\n",
      "Epoch 287/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7717e-05\n",
      "Epoch 288/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6707e-05\n",
      "Epoch 289/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7185e-05\n",
      "Epoch 290/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7314e-05\n",
      "Epoch 291/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0217e-05\n",
      "Epoch 292/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5950e-05\n",
      "Epoch 293/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5355e-05\n",
      "Epoch 294/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6090e-05\n",
      "Epoch 295/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6543e-05\n",
      "Epoch 296/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8096e-05\n",
      "Epoch 297/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6263e-05\n",
      "Epoch 298/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8869e-05\n",
      "Epoch 299/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5890e-05\n",
      "Epoch 300/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6583e-05\n",
      "Epoch 301/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7828e-05\n",
      "Epoch 302/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6188e-05\n",
      "Epoch 303/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4857e-05\n",
      "Epoch 304/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5104e-05\n",
      "Epoch 305/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4295e-05\n",
      "Epoch 306/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4096e-05\n",
      "Epoch 307/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5557e-05\n",
      "Epoch 308/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5691e-05\n",
      "Epoch 309/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6048e-05\n",
      "Epoch 310/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6336e-05\n",
      "Epoch 311/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7053e-05\n",
      "Epoch 312/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5531e-05\n",
      "Epoch 313/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6429e-05\n",
      "Epoch 314/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6093e-05\n",
      "Epoch 315/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6726e-05\n",
      "Epoch 316/600\n",
      "747/747 [==============================] - 9s 12ms/step - loss: 5.4401e-05\n",
      "Epoch 317/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4352e-05\n",
      "Epoch 318/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5276e-05\n",
      "Epoch 319/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6509e-05\n",
      "Epoch 320/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5813e-05\n",
      "Epoch 321/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5012e-05\n",
      "Epoch 322/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0563e-05\n",
      "Epoch 323/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4754e-05\n",
      "Epoch 324/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4831e-05\n",
      "Epoch 325/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5153e-05\n",
      "Epoch 326/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5153e-05\n",
      "Epoch 327/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5260e-05\n",
      "Epoch 328/600\n",
      "747/747 [==============================] - 9s 12ms/step - loss: 5.5291e-05\n",
      "Epoch 329/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3871e-05\n",
      "Epoch 330/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4020e-05\n",
      "Epoch 331/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4319e-05\n",
      "Epoch 332/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3648e-05\n",
      "Epoch 333/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4270e-05\n",
      "Epoch 334/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8972e-05\n",
      "Epoch 335/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5375e-05\n",
      "Epoch 336/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5360e-05\n",
      "Epoch 337/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9143e-05\n",
      "Epoch 338/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6552e-05\n",
      "Epoch 339/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7425e-05\n",
      "Epoch 340/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9488e-05\n",
      "Epoch 341/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5238e-05\n",
      "Epoch 342/600\n",
      "747/747 [==============================] - 9s 12ms/step - loss: 5.4467e-05\n",
      "Epoch 343/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4849e-05\n",
      "Epoch 344/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3963e-05\n",
      "Epoch 345/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3439e-05\n",
      "Epoch 346/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3158e-05\n",
      "Epoch 347/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3135e-05\n",
      "Epoch 348/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3490e-05\n",
      "Epoch 349/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2537e-05\n",
      "Epoch 350/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3690e-05\n",
      "Epoch 351/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5430e-05\n",
      "Epoch 352/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6457e-05\n",
      "Epoch 353/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4954e-05\n",
      "Epoch 354/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5819e-05\n",
      "Epoch 355/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4872e-05\n",
      "Epoch 356/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6159e-05\n",
      "Epoch 357/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4973e-05\n",
      "Epoch 358/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3885e-05\n",
      "Epoch 359/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3239e-05\n",
      "Epoch 360/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2549e-05\n",
      "Epoch 361/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4801e-05\n",
      "Epoch 362/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3595e-05\n",
      "Epoch 363/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3369e-05\n",
      "Epoch 364/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4199e-05\n",
      "Epoch 365/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5500e-05\n",
      "Epoch 366/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7284e-05\n",
      "Epoch 367/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6656e-05\n",
      "Epoch 368/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7079e-05\n",
      "Epoch 369/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7373e-05\n",
      "Epoch 370/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7683e-05\n",
      "Epoch 371/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 6.0685e-05\n",
      "Epoch 372/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8065e-05\n",
      "Epoch 373/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.6129e-05\n",
      "Epoch 374/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5640e-05\n",
      "Epoch 375/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4422e-05\n",
      "Epoch 376/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3491e-05\n",
      "Epoch 377/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2824e-05\n",
      "Epoch 378/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2784e-05\n",
      "Epoch 379/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3423e-05\n",
      "Epoch 380/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2508e-05\n",
      "Epoch 381/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4340e-05\n",
      "Epoch 382/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2371e-05\n",
      "Epoch 383/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2613e-05\n",
      "Epoch 384/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5271e-05\n",
      "Epoch 385/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3032e-05\n",
      "Epoch 386/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4782e-05\n",
      "Epoch 387/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4056e-05\n",
      "Epoch 388/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5459e-05\n",
      "Epoch 389/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7247e-05\n",
      "Epoch 390/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.8031e-05\n",
      "Epoch 391/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5617e-05\n",
      "Epoch 392/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4605e-05\n",
      "Epoch 393/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3641e-05\n",
      "Epoch 394/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4366e-05\n",
      "Epoch 395/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3170e-05\n",
      "Epoch 396/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3405e-05\n",
      "Epoch 397/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4052e-05\n",
      "Epoch 398/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2839e-05\n",
      "Epoch 399/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2020e-05\n",
      "Epoch 400/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.1669e-05\n",
      "Epoch 401/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2189e-05\n",
      "Epoch 402/600\n",
      "747/747 [==============================] - 9s 12ms/step - loss: 5.2400e-05\n",
      "Epoch 403/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2129e-05\n",
      "Epoch 404/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.1777e-05\n",
      "Epoch 405/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3835e-05\n",
      "Epoch 406/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.1717e-05\n",
      "Epoch 407/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2853e-05\n",
      "Epoch 408/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4224e-05\n",
      "Epoch 409/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7137e-05\n",
      "Epoch 410/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7651e-05\n",
      "Epoch 411/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.9986e-05\n",
      "Epoch 412/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.7542e-05\n",
      "Epoch 413/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.5207e-05\n",
      "Epoch 414/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3523e-05\n",
      "Epoch 415/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.2793e-05\n",
      "Epoch 416/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.1983e-05\n",
      "Epoch 417/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.1202e-05\n",
      "Epoch 418/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.1028e-05\n",
      "Epoch 419/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.0862e-05\n",
      "Epoch 420/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.1329e-05\n",
      "Epoch 421/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.4877e-05\n",
      "Epoch 422/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.1577e-05\n",
      "Epoch 423/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3672e-05\n",
      "Epoch 424/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.1779e-05\n",
      "Epoch 425/600\n",
      "747/747 [==============================] - 9s 11ms/step - loss: 5.3876e-05\n",
      "Epoch 426/600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-293-76c77ed9b5d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=batch_size, epochs=epochs, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of RSS and TSS to find out the r2 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 0 \n",
    "c = 0\n",
    "TSS = 0\n",
    "RSS = 0\n",
    "y_train_av = 0\n",
    "AVMat = np.zeros((100,100))\n",
    "\n",
    "for i in range(185):\n",
    "    AVMat = AVMat +  (y_ts[i].reshape(100,100))\n",
    "    \n",
    "AVMat = AVMat/185\n",
    "\n",
    "for i in range(185):\n",
    "    b = ((y_ts[i].reshape(100,100) - preds[i].reshape(100,100))**2)\n",
    "    RSS = RSS + b\n",
    "\n",
    "\n",
    "\n",
    "for i in range(185):\n",
    "    c = ((y_ts[i].reshape(100,100) -  AVMat)**2)\n",
    "    TSS = TSS + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = 1 - (RSS/TSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7672814688125347"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
